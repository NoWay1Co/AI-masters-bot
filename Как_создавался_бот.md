# Как создавался бот-консультант для абитуриентов ИТМО

## Обзор задачи

Передо мной стояла задача создать телеграм-бота, который поможет абитуриентам разобраться с магистерскими программами ИТМО по ИИ. Нужно было реализовать парсинг данных с сайтов, диалоговую систему для ответов на вопросы и персональные рекомендации по выборочным дисциплинам.

Конкретно требовалось:
1. Парсить учебные планы с двух страниц программ
2. Создать диалоговую систему на базе telegram-бота  
3. Генерировать рекомендации по выборочным дисциплинам
4. Отвечать только на релевантные вопросы по обучению

## Выбор технологического стека

### Основные технологии

**Python 3.9+**

**aiogram 3.13.0** - современная асинхронная библиотека для работы с Telegram Bot API. Выбрал именно третью версию из-за улучшенной архитектуры с роутерами и FSM, что делает код более структурированным.

**Ollama + локальная LLM** - принял решение использовать локальную модель вместо API по нескольким причинам:
- Полный контроль над данными
- Отсутствие затрат на API
- Гибкость в настройке промптов

**httpx + BeautifulSoup** - для парсинга веб-страниц. httpx выбрал вместо requests из-за нативной асинхронности, а BeautifulSoup остается стандартом для парсинга HTML.

**pypdf, python-docx, openpyxl** - для обработки файлов учебных планов в разных форматах (взял несколько форматов с заделом на будущее).

**Pydantic** - для валидации данных и создания строго типизированных моделей.

### Архитектурные решения

Выбрал модульную архитектуру с разделением на слои:

```
src/
├── bot/           # Логика телеграм-бота
├── services/      # Бизнес-логика
├── data/          # Модели и хранение данных
└── utils/         # Вспомогательные утилиты
```

Такая структура позволяет легко тестировать компоненты и расширять функциональность.

## Архитектура проекта

### Структура и иерархия

Проект построен по принципу разделения ответственности:

**bot/** - содержит всю логику telegram-бота:
- handlers/ - обработчики разных типов сообщений (start.py, qa.py, recommendations.py)
- keyboards/ - inline-клавиатуры для навигации
- middlewares/ - промежуточные обработчики (логирование)
- states/ - состояния FSM для диалоговых цепочек

**services/** - бизнес-логика приложения:
- parser_service.py - парсинг сайтов и файлов
- llm_service.py - взаимодействие с языковой моделью
- recommendation_service.py - генерация рекомендаций
- cache_service.py - кэширование данных

**data/** - работа с данными:
- models.py - Pydantic модели (Program, Course, UserProfile)
- json_storage.py - простое файловое хранилище

### Поток данных

1. При запуске бот парсит программы (учебные планы) и сохраняет в JSON
2. Пользователь создает профиль через диалог
3. На основе профиля и отпарсеных данных формируется контекст для LLM
4. Генерируются персональные рекомендации/ответ на вопрос

## Парсинг файлов и данных

### Многоуровневая стратегия парсинга

Столкнулся с проблемой - сайты ИТМО используют динамическую загрузку, и прямой парсинг HTML не всегда дает результат. Реализовал многоуровневый подход:

**Уровень 1:** Поиск в JSON данных страницы (Next.js __NEXT_DATA__)
Многие современные сайты хранят данные в JSON прямо в HTML. Ищу поле academic_plan в этих данных.

**Уровень 2:** Анализ JavaScript кода
Если JSON не содержит ссылок, анализирую встроенный JavaScript на предмет URL файлов с учебными планами.

**Уровень 3:** Традиционный парсинг HTML
Ищу ссылки по тексту ("Скачать учебный план") и проверяю расширения файлов.

**Fallback:** Mock данные
Если парсинг не дает результатов, использую заранее подготовленные демо-данные для демонстрации функциональности.

### Обработка разных форматов файлов

Учебные планы могут быть в PDF, DOCX или XLSX. Для каждого формата реализовал свой парсер:

**PDF:** Использую pypdf для извлечения текста, затем ищу паттерны курсов с помощью регулярных выражений.

**DOCX:** Парсю и текст параграфов, и таблицы. Часто структура более четкая, чем в PDF.

**XLSX:** Самый структурированный формат. Ищу заголовки колонок и извлекаю данные по строкам.

### Извлечение информации о курсах

Основная сложность - разнообразие форматов записи курсов. Использую несколько паттернов:
- Семестр + Название + Кредиты + Часы
- Название + Кредиты + Часы

Фильтрую нереалистичные значения и валидирую названия курсов.

## Формирование контекста для LLM

### Персонализация контекста

Контекст для LLM строю в зависимости от типа запроса:

**Для рекомендаций:**
- Профиль пользователя (образование, интересы, цели)
- Полное описание программ с курсами
- Структурированное описание выборочных дисциплин

**Для ответов на вопросы:**
- Краткий контекст с релевантными данными
- Ограничение размера для быстрой работы (15000 символов)
- Фильтрация курсов по ключевым словам из вопроса

### Оптимизация производительности

LLM может работать медленно с большими контекстами. Применяю несколько стратегий:

**Сжатие контекста:** Для Q&A режима ограничиваю размер контекста и отсекаю лишнее.

**Многоуровневый поиск:** Сначала пытаюсь найти ответ в данных напрямую, укарачивая получаемый контекст данных и только потом обращаюсь к LLM.

**Кэширование:** Результаты парсинга данных в json-ах кэширую на несколько часов.

## Система рекомендаций

### Алгоритм подбора программ

Для генерации рекомендаций анализирую:
1. Ключевые слова в интересах пользователя
2. Соответствие выборочных дисциплин интересам  
3. Опыт и цели пользователя

Если LLM-ка недоступна, использую fallback-логику - простое сопоставление ключевых слов.

# Примечание: 
Рекомендательная система реализована через локальную LLM, но эту задачу также можно было реализовать в виде теста, который проходит юзер и на основании него выдается результат на какое направление лучше пойти, но так как временные рамки накладывают временное ограничение, было принято решение остановиться на LLM.

### Персонализация выборочных дисциплин

Для каждого пользователя фильтрую выборочные курсы:
- Ищу пересечения между интересами и названиями курсов
- Учитываю семестр и сложность
- Ограничиваю количество рекомендаций 3-5 курсами

## Диалоговая система

### FSM для управления состояниями

Использую конечный автомат состояний aiogram для управления диалогами:

**COLLECTING_BACKGROUND** → **COLLECTING_INTERESTS** → **COLLECTING_GOALS** → **MAIN_MENU**

Каждое состояние обрабатывает свой тип ввода и переводит в следующее.

### Ответов на вопрос режим с фильтрацией

Реализовал систему фильтрации вопросов. Проверяю релевантность по запрещенным ключевым словам (погода, политика, игры).

Если вопрос релевантный, применяю трехуровневую стратегию ответа:
1. LLM с полным контекстом
2. Поиск в данных напрямую
3. Общий LLM без контекста
4. Fallback-ответ

### Обработка ошибок

Во всех критических местах добавил обработку исключений с логированием. Если что-то не работает, пользователь получает понятное сообщение, а не технические ошибки.

## Основные технические решения

### Асинхронная архитектура

Все операции ввода-вывода (парсинг, LLM, файловые операции) сделал асинхронными. Это критично для telegram-бота, который должен обрабатывать множество пользователей.

### Логирование и мониторинг

Использую structlog для структурированного логирования. Это помогает отслеживать работу парсера, производительность LLM и поведение пользователей.

### Конфигурация через переменные окружения

Все настройки (токены, URL модели, пути) выношу в .env файл через python-decouple. Это упрощает развертывание в разных средах.

### Graceful degradation

Система работает даже при отказе отдельных компонентов:
- Нет Ollama - показываем fallback-ответы
- Не получилось спарсить - используем mock-данные  
- LLM не отвечает - применяем простую логику поиска

## Решение основных задач

### 1. Парсинг данных с сайтов

Реализовал автоматический парсинг при запуске бота. Система ищет учебные планы на страницах программ, скачивает файлы и извлекает структурированные данные о курсах.

### 2. Диалоговая система

Создал интуитивную навигацию через inline-клавиатуры. Пользователь проходит через создание профиля, затем может задавать вопросы или получать рекомендации.

### 3. Персональные рекомендации

На основе профиля пользователя бот рекомендует подходящую программу и выборочные дисциплины. Использую как LLM для детального анализа, так и правила для базовой логики.

### 4. Фильтрация релевантных вопросов

Бот отвечает только на вопросы об обучении. Нерелевантные вопросы отфильтровываются, а также стоп-слова для промпт-инжиниринга, или пользователю предлагается переформулировать запрос.

## Выводы и результат

Получился функциональный бот, который решает поставленные задачи. Архитектура позволяет легко добавлять новые программы и расширять функциональность.


TLDR:
Первым шагом были определены функциональные требования для бота, по которым подобран стек технологий.
Так как в регламенте было разрешено использование ИИ-инструментов, был сформирован сформировать бэклог задач для агентного режима, с подробным описанием всех функций, code-snippet-ами и критериями приемки и тестирования.
Далее в несколько этапов производилась разработка бота, с тщательной ревизией кода который написал агент.
На каждом этапе производился коммит изменений, для возможности отката в случае проблем и linter ошибок и прочих проблем при использовании ИИ агентов
В качестве инструментов использовалась Cursor IDE вместе с агентным режимом для ускорение работы.